{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7788213-9cfe-4787-a6f8-d8d6cc426070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92a592c-e822-4070-9dd3-10610106e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions==4.4.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions==4.4.0\n",
    "import typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ed03d-6320-4073-b045-fd89427049fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89059a8f-4cf8-45dd-8efd-22638ccbd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "array = torch.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c3b412-f4c9-401f-a52e-5d7365a33709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.24.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym==0.24.0) (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym==0.24.0) (1.20.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym==0.24.0) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym==0.24.0) (0.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from importlib-metadata>=4.8.0->gym==0.24.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905b9cc6-9a0c-4fd2-a40b-1cb3f7b76926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[classic_control]==0.24.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym[classic_control]==0.24.0) (1.20.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym[classic_control]==0.24.0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym[classic_control]==0.24.0) (4.8.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym[classic_control]==0.24.0) (2.0.0)\n",
      "Requirement already satisfied: pygame==2.1.0 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from gym[classic_control]==0.24.0) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\programs\\anaconda3\\conda\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[classic_control]==0.24.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[classic_control]==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7741d2b0-1d63-4384-865a-df93231b2d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5e96ff-01ce-443b-b65b-5601962d73e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v1', 'CarRacingDomainRandomize-v1', 'CarRacingDiscrete-v1', 'CarRacingDomainRandomizeDiscrete-v1', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.envs.registry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2244645-aa89-4e04-b211-8b9c35c420db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "state_dim = 4\n",
    "action_n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf606f5-447d-407c-aeea-eb89e287273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_trajectory(env, agent, max_len = 1000, visualise = False):\n",
    "    trajectory = {'states': [], 'actions' : [], 'rewards' : []}\n",
    "    \n",
    "    state = env.reset()\n",
    "\n",
    "    #create traectory\n",
    "    for _ in range(max_len):\n",
    "        trajectory['states'].append(state)\n",
    "        \n",
    "        action = agent.get_action(state)\n",
    "        trajectory['actions'].append(action)\n",
    "        \n",
    "        state, reward, done, _ = env.step(action)\n",
    "        trajectory['rewards'].append(reward)\n",
    "\n",
    "        \n",
    "        if visualise:\n",
    "            time.sleep(.1)\n",
    "            env.render()\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db78598-6e10-42d4-bba9-d41d8b3de8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent():\n",
    "    def __init__(self, action_n):\n",
    "        self.action_n = action_n\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        action = np.random.randint(self.action_n)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af54256-b75b-4cf0-9df7-72012e6f93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RandomAgent(action_n)\n",
    "get_trajectory(env, agent, visualise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdafbb96-fc8b-46fd-b817-967f5d6b29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM(nn.Module):\n",
    "    def __init__(self, state_n, action_n):\n",
    "        super().__init__()\n",
    "        self.action_n = action_n\n",
    "        self.state_n = state_n\n",
    "        self.network = nn.Sequential(nn.Linear(self.state_n, 128), nn.ReLU(), nn.Linear(128, self.action_n))\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = .01)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, _input):\n",
    "        return self.network(_input)\n",
    "     \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state)\n",
    "        probs = self.softmax(self.forward(state)).data.numpy()\n",
    "        action = np.random.choice(self.action_n, p = probs)\n",
    "        return action\n",
    "    \n",
    "    def fit(self, elite_tr):\n",
    "        elite_states = []\n",
    "        elite_actions = []\n",
    "        \n",
    "        for tr in elite_tr:\n",
    "            for state, action in zip(tr['states'], tr['actions']):\n",
    "                elite_states.append(state)\n",
    "                elite_actions.append(action)\n",
    "        elite_states = torch.FloatTensor(elite_states)\n",
    "        elite_actions = torch.LongTensor(elite_actions)\n",
    "        \n",
    "        pred_acts = self.forward(elite_states)\n",
    "        loss = self.loss(pred_acts, elite_actions)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28a92ca-311c-40ea-bbd8-30ea229b012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\anaconda3\\conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 mean total reward 22.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\81E4~1\\AppData\\Local\\Temp/ipykernel_12952/3188902186.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  elite_states = torch.FloatTensor(elite_states)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 mean total reward 31.54\n",
      "iter 2 mean total reward 33.82\n",
      "iter 3 mean total reward 35.98\n",
      "iter 4 mean total reward 38.68\n",
      "iter 5 mean total reward 47.62\n",
      "iter 6 mean total reward 53.8\n",
      "iter 7 mean total reward 48.0\n",
      "iter 8 mean total reward 64.84\n",
      "iter 9 mean total reward 58.02\n",
      "iter 10 mean total reward 71.78\n",
      "iter 11 mean total reward 69.96\n",
      "iter 12 mean total reward 88.04\n",
      "iter 13 mean total reward 75.46\n",
      "iter 14 mean total reward 70.96\n",
      "iter 15 mean total reward 80.64\n",
      "iter 16 mean total reward 83.88\n",
      "iter 17 mean total reward 88.4\n",
      "iter 18 mean total reward 116.74\n",
      "iter 19 mean total reward 130.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'states': [array([-0.03111615,  0.04042187, -0.03767826, -0.01783415], dtype=float32),\n",
       "  array([-0.03030772, -0.15414004, -0.03803494,  0.26272678], dtype=float32),\n",
       "  array([-0.03339051, -0.34869903, -0.03278041,  0.5431746 ], dtype=float32),\n",
       "  array([-0.0403645 , -0.1531321 , -0.02191691,  0.2403461 ], dtype=float32),\n",
       "  array([-0.04342714, -0.34793422, -0.01710999,  0.526036  ], dtype=float32),\n",
       "  array([-0.05038582, -0.15257573, -0.00658927,  0.22801113], dtype=float32),\n",
       "  array([-0.05343734,  0.04263976, -0.00202905, -0.06674299], dtype=float32),\n",
       "  array([-0.05258454, -0.15245304, -0.00336391,  0.22529908], dtype=float32),\n",
       "  array([-0.0556336 ,  0.04271682,  0.00114208, -0.06844305], dtype=float32),\n",
       "  array([-0.05477927, -0.15242147, -0.00022679,  0.22459999], dtype=float32),\n",
       "  array([-0.0578277 , -0.3475402 ,  0.00426521,  0.5172114 ], dtype=float32),\n",
       "  array([-0.0647785 , -0.15247856,  0.01460944,  0.22587554], dtype=float32),\n",
       "  array([-0.06782807, -0.34780622,  0.01912695,  0.5231308 ], dtype=float32),\n",
       "  array([-0.0747842 , -0.15295862,  0.02958957,  0.23653583], dtype=float32),\n",
       "  array([-0.07784337, -0.34849054,  0.03432029,  0.5384034 ], dtype=float32),\n",
       "  array([-0.08481318, -0.15386747,  0.04508835,  0.2567289 ], dtype=float32),\n",
       "  array([-0.08789053, -0.34960318,  0.05022293,  0.5632855 ], dtype=float32),\n",
       "  array([-0.09488259, -0.1552206 ,  0.06148864,  0.28683865], dtype=float32),\n",
       "  array([-0.097987  ,  0.03897301,  0.06722542,  0.014165  ], dtype=float32),\n",
       "  array([-0.09720755, -0.15704541,  0.06750871,  0.3272779 ], dtype=float32),\n",
       "  array([-0.10034845,  0.03705373,  0.07405427,  0.05662486], dtype=float32),\n",
       "  array([-0.09960738, -0.15904762,  0.07518677,  0.37172273], dtype=float32),\n",
       "  array([-0.10278833,  0.03493015,  0.08262122,  0.10366222], dtype=float32),\n",
       "  array([-0.10208973, -0.16127269,  0.08469447,  0.42122555], dtype=float32),\n",
       "  array([-0.10531518,  0.03255358,  0.09311898,  0.15639871], dtype=float32),\n",
       "  array([-0.10466411, -0.1637697 ,  0.09624696,  0.47694522], dtype=float32),\n",
       "  array([-0.1079395 ,  0.02987091,  0.10578586,  0.21608154], dtype=float32),\n",
       "  array([-0.10734209,  0.22333401,  0.11010749, -0.04144783], dtype=float32),\n",
       "  array([-0.1028754 ,  0.0268195 ,  0.10927854,  0.28384513], dtype=float32),\n",
       "  array([-0.10233901,  0.22022693,  0.11495544,  0.02752846], dtype=float32),\n",
       "  array([-0.09793448,  0.41352874,  0.11550601, -0.22678801], dtype=float32),\n",
       "  array([-0.0896639 ,  0.21696179,  0.11097024,  0.09998102], dtype=float32),\n",
       "  array([-0.08532467,  0.41033286,  0.11296987, -0.15573314], dtype=float32),\n",
       "  array([-0.07711801,  0.21378991,  0.1098552 ,  0.17034456], dtype=float32),\n",
       "  array([-0.07284221,  0.01728105,  0.11326209,  0.4955635 ], dtype=float32),\n",
       "  array([-0.07249659,  0.21063887,  0.12317336,  0.24061304], dtype=float32),\n",
       "  array([-0.06828381,  0.40380573,  0.12798563, -0.01082055], dtype=float32),\n",
       "  array([-0.0602077 ,  0.20710275,  0.12776922,  0.3193458 ], dtype=float32),\n",
       "  array([-0.05606564,  0.40019545,  0.13415614,  0.06952973], dtype=float32),\n",
       "  array([-0.04806173,  0.59316444,  0.13554673, -0.17799918], dtype=float32),\n",
       "  array([-0.03619844,  0.78611255,  0.13198674, -0.42503783], dtype=float32),\n",
       "  array([-0.02047619,  0.5893921 ,  0.12348598, -0.09383214], dtype=float32),\n",
       "  array([-0.00868835,  0.7825477 ,  0.12160935, -0.34514657], dtype=float32),\n",
       "  array([ 0.0069626 ,  0.5859246 ,  0.11470641, -0.0167251 ], dtype=float32),\n",
       "  array([0.0186811 , 0.38936046, 0.11437191, 0.30983335], dtype=float32),\n",
       "  array([0.0264683 , 0.19281052, 0.12056857, 0.6362842 ], dtype=float32),\n",
       "  array([0.03032452, 0.386063  , 0.13329425, 0.38387117], dtype=float32),\n",
       "  array([0.03804578, 0.57906556, 0.14097168, 0.13600796], dtype=float32),\n",
       "  array([ 0.04962709,  0.7719164 ,  0.14369184, -0.10909013], dtype=float32),\n",
       "  array([0.06506541, 0.575059  , 0.14151004, 0.22525299], dtype=float32),\n",
       "  array([ 0.07656659,  0.76790476,  0.1460151 , -0.01965895], dtype=float32),\n",
       "  array([ 0.09192469,  0.96066374,  0.14562193, -0.26294458], dtype=float32),\n",
       "  array([ 0.11113796,  1.1534394 ,  0.14036302, -0.50638586], dtype=float32),\n",
       "  array([ 0.13420676,  0.95664763,  0.13023531, -0.17296992], dtype=float32),\n",
       "  array([ 0.1533397,  1.1496885,  0.1267759, -0.4218979], dtype=float32),\n",
       "  array([ 0.17633347,  1.3428078 ,  0.11833795, -0.6720797 ], dtype=float32),\n",
       "  array([ 0.20318963,  1.1462569 ,  0.10489636, -0.34460524], dtype=float32),\n",
       "  array([ 0.22611476,  0.94981134,  0.09800426, -0.0207735 ], dtype=float32),\n",
       "  array([ 0.24511099,  1.1434011 ,  0.09758878, -0.28099766], dtype=float32),\n",
       "  array([0.26797903, 0.94703245, 0.09196883, 0.04079954], dtype=float32),\n",
       "  array([0.28691965, 0.75072026, 0.09278482, 0.36102408], dtype=float32),\n",
       "  array([0.30193406, 0.94440925, 0.10000531, 0.09897988], dtype=float32),\n",
       "  array([ 0.32082227,  1.1379663 ,  0.1019849 , -0.16055252], dtype=float32),\n",
       "  array([ 0.3435816 ,  1.3314916 ,  0.09877385, -0.41940045], dtype=float32),\n",
       "  array([ 0.37021142,  1.5250853 ,  0.09038585, -0.67938334], dtype=float32),\n",
       "  array([ 0.40071312,  1.7188432 ,  0.07679818, -0.9422965 ], dtype=float32),\n",
       "  array([ 0.43508998,  1.522775  ,  0.05795225, -0.6265047 ], dtype=float32),\n",
       "  array([ 0.46554548,  1.7170422 ,  0.04542215, -0.9003879 ], dtype=float32),\n",
       "  array([ 0.49988633,  1.9115202 ,  0.02741439, -1.1784545 ], dtype=float32),\n",
       "  array([ 0.53811675,  1.7160532 ,  0.0038453 , -0.87730527], dtype=float32),\n",
       "  array([ 0.5724378,  1.5208793, -0.0137008, -0.5834159], dtype=float32),\n",
       "  array([ 0.6028554 ,  1.3259519 , -0.02536912, -0.29508024], dtype=float32),\n",
       "  array([ 0.62937444,  1.1312007 , -0.03127073, -0.01050508], dtype=float32),\n",
       "  array([ 0.65199846,  1.3267567 , -0.03148083, -0.31288797], dtype=float32),\n",
       "  array([ 0.67853355,  1.1320971 , -0.03773859, -0.03029699], dtype=float32),\n",
       "  array([ 0.7011755 ,  1.3277394 , -0.03834452, -0.33464393], dtype=float32),\n",
       "  array([ 0.7277303,  1.5233854, -0.0450374, -0.6391679], dtype=float32),\n",
       "  array([ 0.758198  ,  1.7191055 , -0.05782076, -0.94568676], dtype=float32),\n",
       "  array([ 0.7925801 ,  1.5248079 , -0.0767345 , -0.67171735], dtype=float32),\n",
       "  array([ 0.82307625,  1.3308318 , -0.09016884, -0.4041472 ], dtype=float32),\n",
       "  array([ 0.84969294,  1.5271091 , -0.09825179, -0.72384083], dtype=float32),\n",
       "  array([ 0.8802351,  1.3334734, -0.1127286, -0.4636276], dtype=float32),\n",
       "  array([ 0.9069046 ,  1.1401099 , -0.12200116, -0.20849542], dtype=float32),\n",
       "  array([ 0.92970675,  1.336746  , -0.12617107, -0.5370366 ], dtype=float32),\n",
       "  array([ 0.9564417 ,  1.1436027 , -0.1369118 , -0.28662062], dtype=float32),\n",
       "  array([ 0.97931373,  0.9506719 , -0.14264421, -0.04005888], dtype=float32),\n",
       "  array([ 0.9983272 ,  1.1475207 , -0.14344539, -0.37412837], dtype=float32),\n",
       "  array([ 1.0212775 ,  0.9546966 , -0.15092796, -0.12989143], dtype=float32),\n",
       "  array([ 1.0403715 ,  0.7620227 , -0.15352578,  0.1116294 ], dtype=float32),\n",
       "  array([ 1.055612  ,  0.9589731 , -0.15129319, -0.22528094], dtype=float32),\n",
       "  array([ 1.0747914 ,  1.1558971 , -0.15579881, -0.5616034 ], dtype=float32),\n",
       "  array([ 1.0979093 ,  1.3528228 , -0.16703089, -0.8990339 ], dtype=float32),\n",
       "  array([ 1.1249658 ,  1.1603103 , -0.18501157, -0.66316307], dtype=float32),\n",
       "  array([ 1.148172  ,  1.3574582 , -0.19827482, -1.007922  ], dtype=float32)],\n",
       " 'actions': [0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1],\n",
       " 'rewards': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = CEM(state_dim, action_n)\n",
    "trajectory_len = 500\n",
    "trajectory_n = 50\n",
    "iteration_n = 20\n",
    "q_param = .9\n",
    "\n",
    "for it in range(iteration_n):\n",
    "    \n",
    "    #policy evaluation\n",
    "    trajectories = [get_trajectory(env, agent) for _ in range(trajectory_n)]\n",
    "    total_reward = [np.sum(i['rewards']) for i in trajectories]\n",
    "    print('iter', it, 'mean total reward', np.mean(total_reward))\n",
    "    \n",
    "    #policy improvement\n",
    "    quantile = np.quantile(total_reward, q_param)\n",
    "    elite_tr = []\n",
    "    for tr in trajectories:\n",
    "        r = np.sum(tr['rewards'])\n",
    "        if r > quantile:\n",
    "            elite_tr.append(tr)\n",
    "            \n",
    "    agent.fit(elite_tr)\n",
    "    \n",
    "get_trajectory(env, agent, visualise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51702f-34c9-4e38-af67-8384299bc33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
